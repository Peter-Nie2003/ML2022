{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":34954,"databundleVersionId":3300998,"sourceType":"competition"}],"dockerImageVersionId":30171,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# If you want to access the version you have already modified, click \"Edit\"\n# If you want to access the original sample code, click \"...\", then click \"Copy & Edit Notebook\"","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:30:57.715159Z","iopub.execute_input":"2024-01-21T16:30:57.715921Z","iopub.status.idle":"2024-01-21T16:30:57.719187Z","shell.execute_reply.started":"2024-01-21T16:30:57.715884Z","shell.execute_reply":"2024-01-21T16:30:57.718319Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"## This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":19.351342,"end_time":"2022-02-23T10:03:06.247288","exception":false,"start_time":"2022-02-23T10:02:46.895946","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-21T16:30:57.720846Z","iopub.execute_input":"2024-01-21T16:30:57.721077Z","iopub.status.idle":"2024-01-21T16:31:21.725675Z","shell.execute_reply.started":"2024-01-21T16:30:57.721048Z","shell.execute_reply":"2024-01-21T16:31:21.724951Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"_exp_name = \"sample\"","metadata":{"papermill":{"duration":0.0189,"end_time":"2022-02-23T10:03:06.279758","exception":false,"start_time":"2022-02-23T10:03:06.260858","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-21T16:31:21.726839Z","iopub.execute_input":"2024-01-21T16:31:21.727081Z","iopub.status.idle":"2024-01-21T16:31:21.731017Z","shell.execute_reply.started":"2024-01-21T16:31:21.727051Z","shell.execute_reply":"2024-01-21T16:31:21.730252Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Import necessary packages.\nimport numpy as np\nimport torch\nimport os\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom PIL import Image\n# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\nfrom torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\nfrom torchvision.datasets import DatasetFolder, VisionDataset\n\n\n# This is for the progress bar.\nfrom tqdm.auto import tqdm\nimport random","metadata":{"papermill":{"duration":1.654263,"end_time":"2022-02-23T10:03:07.947242","exception":false,"start_time":"2022-02-23T10:03:06.292979","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-21T16:31:21.732150Z","iopub.execute_input":"2024-01-21T16:31:21.732394Z","iopub.status.idle":"2024-01-21T16:31:23.286467Z","shell.execute_reply.started":"2024-01-21T16:31:21.732357Z","shell.execute_reply":"2024-01-21T16:31:23.285754Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"myseed = 6666  # set a random seed for reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nnp.random.seed(myseed)\ntorch.manual_seed(myseed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(myseed)","metadata":{"papermill":{"duration":0.078771,"end_time":"2022-02-23T10:03:08.039428","exception":false,"start_time":"2022-02-23T10:03:07.960657","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-21T16:31:23.288365Z","iopub.execute_input":"2024-01-21T16:31:23.288592Z","iopub.status.idle":"2024-01-21T16:31:23.363391Z","shell.execute_reply.started":"2024-01-21T16:31:23.288563Z","shell.execute_reply":"2024-01-21T16:31:23.362563Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## **Transforms**\nTorchvision provides lots of useful utilities for image preprocessing, data wrapping as well as data augmentation.\n\nPlease refer to PyTorch official website for details about different transforms.","metadata":{"papermill":{"duration":0.01289,"end_time":"2022-02-23T10:03:08.065357","exception":false,"start_time":"2022-02-23T10:03:08.052467","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Normally, We don't need augmentations in testing and validation.\n# All we need here is to resize the PIL image and transform it into Tensor.\ntest_tfm = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n])\n\n# However, it is also possible to use augmentation in the testing phase.\n# You may use train_tfm to produce a variety of images and then test using ensemble methods\ntrain_tfm = transforms.Compose([\n    # Resize the image into a fixed shape (height = width = 128)\n    transforms.Resize((128, 128)),\n    transforms.RandomRotation(15),\n    transforms.RandomRotation(30),\n    transforms.ColorJitter(brightness=1),\n    transforms.RandomHorizontalFlip(0.5),\n    transforms.RandomVerticalFlip(0.5),\n    # You may add some transforms here.\n    # ToTensor() should be the last one of the transforms.\n    transforms.ToTensor(),\n])\n","metadata":{"papermill":{"duration":0.021406,"end_time":"2022-02-23T10:03:08.099437","exception":false,"start_time":"2022-02-23T10:03:08.078031","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-21T16:31:23.364507Z","iopub.execute_input":"2024-01-21T16:31:23.364722Z","iopub.status.idle":"2024-01-21T16:31:23.371256Z","shell.execute_reply.started":"2024-01-21T16:31:23.364695Z","shell.execute_reply":"2024-01-21T16:31:23.370525Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## **Datasets**\nThe data is labelled by the name, so we load images and label while calling '__getitem__'","metadata":{"papermill":{"duration":0.012739,"end_time":"2022-02-23T10:03:08.125181","exception":false,"start_time":"2022-02-23T10:03:08.112442","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class FoodDataset(Dataset):\n \n    def __init__(self,path=None,tfm=test_tfm,files=None):\n        super(FoodDataset).__init__()\n        self.path = path\n        if path:\n            self.files = sorted([os.path.join(path, x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n        else:\n            self.files = files\n        self.transform = tfm\n  \n    def __len__(self):\n        return len(self.files)\n  \n    def __getitem__(self,idx):\n        fname = self.files[idx]\n        im = Image.open(fname)\n        im = self.transform(im)\n        #im = self.data[idx]\n        try:\n            label = int(fname.split(\"/\")[-1].split(\"_\")[0])  # windows写成\\\\\n        except:\n            label = -1 # test has no label\n        return im,label\n\n\n","metadata":{"papermill":{"duration":0.023022,"end_time":"2022-02-23T10:03:08.160912","exception":false,"start_time":"2022-02-23T10:03:08.13789","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-21T16:31:23.372525Z","iopub.execute_input":"2024-01-21T16:31:23.372766Z","iopub.status.idle":"2024-01-21T16:31:23.385589Z","shell.execute_reply.started":"2024-01-21T16:31:23.372738Z","shell.execute_reply":"2024-01-21T16:31:23.384941Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n        # input 維度 [3, 128, 128]\n        self.cnn_layer1=nn.Sequential(\n            nn.Conv2d(3, 64, 3, 1, 1),  \n            nn.BatchNorm2d(64),\n            \n        )\n        \n        self.cnn_layer2=nn.Sequential(\n            nn.Conv2d(64, 64, 3, 1, 1), \n            nn.BatchNorm2d(64),\n            \n        )\n        \n        self.cnn_layer3=nn.Sequential(\n            nn.Conv2d(64, 128, 3, 1, 1), \n            nn.BatchNorm2d(128),\n           \n        )\n        \n        self.cnn_layer4=nn.Sequential(\n            nn.Conv2d(128,128, 3, 1, 1), \n            nn.BatchNorm2d(128),\n           \n        )\n        \n        self.cnn_layer5=nn.Sequential(\n            nn.Conv2d(128, 256, 3, 1, 1), \n            nn.BatchNorm2d(256),\n           \n        )\n        self.cnn_layer6=nn.Sequential(\n            nn.Conv2d(256, 256, 3, 1, 1), \n            nn.BatchNorm2d(256),\n           \n        )\n        self.relu=nn.Sequential(\n            nn.ReLU(),\n        )\n        \n        self.maxpool=nn.Sequential(\n            nn.MaxPool2d(2,2,0),\n        )\n        \n        self.fc = nn.Sequential(\n            nn.Linear(256*8*8, 512),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(256, 11)\n        )\n\n    def forward(self, x):\n        x1=self.cnn_layer1(x)\n        x1=self.relu(x1)\n        x1=self.maxpool(x1)\n        residual=x1\n        x2=self.cnn_layer2(x1)\n        x2=self.relu(residual+x2)\n        x2=self.maxpool(x2)\n        x3=self.cnn_layer3(x2)\n        x3=self.relu(x3)\n        x3=self.maxpool(x3)\n        residual=x3\n        x4=self.cnn_layer4(x3)\n        x4=self.relu(residual+x4)\n        x5=self.cnn_layer5(x4)\n        x5=self.relu(x5)\n        residual=x5\n        x6=self.cnn_layer6(x5)\n        x6=self.relu(residual+x6)\n        x6=self.maxpool(x6)\n        xout=x6.flatten(1)\n        return self.fc(xout)\n        \n        \n        \n        ","metadata":{"papermill":{"duration":0.0258,"end_time":"2022-02-23T10:03:08.199437","exception":false,"start_time":"2022-02-23T10:03:08.173637","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-21T16:31:23.386560Z","iopub.execute_input":"2024-01-21T16:31:23.386835Z","iopub.status.idle":"2024-01-21T16:31:23.404783Z","shell.execute_reply.started":"2024-01-21T16:31:23.386806Z","shell.execute_reply":"2024-01-21T16:31:23.404045Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def trainer_k_folds(config, _dataset_dir, batch_size, train_tfm, test_tfm, devices):\n    train_dir = os.path.join(_dataset_dir,\"training\")\n    val_dir = os.path.join(_dataset_dir,\"validation\")\n    train_files = [os.path.join(train_dir, x) for x in os.listdir(train_dir) if x.endswith('.jpg')]\n    val_files = [os.path.join(val_dir, x) for x in os.listdir(val_dir) if x.endswith('.jpg')]\n    total_files = np.array(train_files + val_files)\n    random.shuffle(total_files)\n    num_folds = config['num_folds']   \n    train_folds = np.array_split(np.arange(len(total_files)), num_folds)\n    train_folds = np.array(train_folds, dtype=object) # 防止因为数组维度不整齐而报错\n        \n    for i in range(2,5):\n        print(f'\\n\\nStarting Fold: {i} ********************************************')  \n        train_data = total_files[np.concatenate(np.delete(train_folds, i)) ] \n        val_data = total_files[train_folds[i]]        \n    \n        train_set = FoodDataset(tfm=train_tfm, files=train_data)\n        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last = True)    \n        valid_set = FoodDataset(tfm=test_tfm, files=val_data)\n        valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last = True)\n        print('训练集总长度是 {:d}, batch数量是 {:.2f}'.format(len(train_set), len(train_set)/ batch_size))\n        print('验证集总长度是 {:d}, batch数量是 {:.2f}'.format(len(valid_set), len(valid_set)/ batch_size))\n        \n        tep = config['model_path']\n        config['model_path'] += f\"Fold_{i}_best\"\n        config['best_acc'] = 0.0\n        model = Classifier().to(devices)\n        # model.load_state_dict(torch.load('models/foldmodel0.0001')) 提前训练几个epoch，可能加快后面每一个模型的训练\n        trainer(train_loader, valid_loader, model, config, devices)\n        config['best_accs'].append(config['best_acc'])\n        config['model_path'] = tep\n\n\nbatch_size = 512\n_dataset_dir = \"../input/ml2022spring-hw3b/food11\"\n# Construct datasets.\n# The argument \"loader\" tells how torchvision reads the data.\ntrain_set = FoodDataset(os.path.join(_dataset_dir,\"training\"), tfm=train_tfm)\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\nvalid_set = FoodDataset(os.path.join(_dataset_dir,\"validation\"), tfm=test_tfm)\nvalid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n\n \nconfig = {\n    # training prarameters\n    'num_epoch': 300,             # the number of training epoch\n    'learning_rate': 5e-4,          # learning rate \n    'weight_decay': 1e-4, \n    'best_acc': 0.0,\n    'T_0': 16,\n    'T_mult': 1,    \n    'eta_min_ratio':50,\n    'patience': 32, \n    'num_folds':5,\n    'show_num': 1,\n    'best_accs': []\n}\nconfig['model_path'] = './models22/model' + str(config['learning_rate']) # the path where the checkpoint will be saved\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = Classifier().to(device)\n\ndef trainer(train_loader, val_loader, model, config, devices):  \n    \n    criterion = nn.CrossEntropyLoss() \n    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, \n                T_0=config['T_0'], T_mult=config['T_mult'], \n                eta_min=config['learning_rate']/config['eta_min_ratio'])\n    n_epochs, patience = config['num_epoch'], config['patience']\n    num_batches = len(train_loader)\n    show_batches = num_batches // config['show_num']\n    \n    if not os.path.isdir('./' + config['model_path'].split('/')[1]):\n        os.mkdir('./' + config['model_path'].split('/')[1]) # Create directory of saving models.\n    legend = ['train loss', 'train acc']\n    \n    if val_loader is not None:\n        legend.append('valid loss')  \n        legend.append('valid acc')  \n         \n        \n    for epoch in range(n_epochs):\n        train_acc, train_loss = 0.0, 0.0        \n        \n        # training\n        model.train() # set the model to training mode\n        for i, (data, labels) in enumerate(train_loader):\n            data, labels = data.to(devices), labels.to(devices)         \n \n            optimizer.zero_grad() \n            outputs = model(data)             \n            \n            loss = criterion(outputs, labels)\n            loss.backward() \n            optimizer.step() \n \n            _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n            train_acc += (train_pred.detach() == labels.detach()).sum().item()\n            train_loss += loss.item()            \n        \n            if (i + 1) % show_batches == 0:\n                train_acc = train_acc / show_batches / len(data)\n                train_loss = train_loss / show_batches\n                print('train_acc {:.3f}, train_loss {:.3f}'.format(train_acc, train_loss))\n                train_acc, train_loss = 0.0, 0.0               \n                \n        scheduler.step()\n        # validation\n        if val_loader != None:\n            model.eval() # set the model to evaluation mode\n            val_acc, val_loss = 0.0, 0.0  \n            with torch.no_grad():\n                for i, (data, labels) in enumerate(val_loader):\n                    data, labels = data.to(devices), labels.to(devices)\n                    outputs = model(data)\n                                        \n                    loss = criterion(outputs, labels) \n \n                    _, val_pred = torch.max(outputs, 1) \n                    val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n                    val_loss += loss.item()                \n \n                val_acc = val_acc / len(val_loader) / len(data)\n                val_loss = val_loss / len(val_loader)\n                print('val_acc {:.3f}, val_loss {:.3f} '.format(val_acc, val_loss))\n               \n                \n                # if the model improves, save a checkpoint at this epoch\n                if val_acc > config['best_acc']:\n                    config['best_acc'] = val_acc\n                    torch.save(model.state_dict(),  config['model_path'])\n                    # print('saving model with acc {:.3f}'.format(best_acc / len(val_loader) / len(labels)))\n                    stale = 0\n                else:\n                    stale += 1\n                    if stale > patience:\n                        print(f\"No improvment {patience} consecutive epochs, early stopping\")\n                        break\n \n    # if not validating, save the last epoch\n    if val_loader == None:\n        torch.save(model.state_dict(), config['model_path'])\n        # print('saving model at last epoch')  \n\ntrainer_k_folds(config, _dataset_dir, batch_size, train_tfm, test_tfm, device)\n","metadata":{"papermill":{"duration":0.054295,"end_time":"2022-02-23T10:03:08.266338","exception":false,"start_time":"2022-02-23T10:03:08.212043","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-21T16:31:23.406198Z","iopub.execute_input":"2024-01-21T16:31:23.406527Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\n\nStarting Fold: 2 ********************************************\n训练集总长度是 10637, batch数量是 20.78\n验证集总长度是 2659, batch数量是 5.19\ntrain_acc 0.123, train_loss 2.943\nval_acc 0.135, val_loss 2.314 \ntrain_acc 0.153, train_loss 2.316\nval_acc 0.161, val_loss 2.305 \ntrain_acc 0.173, train_loss 2.273\nval_acc 0.175, val_loss 2.277 \ntrain_acc 0.205, train_loss 2.221\nval_acc 0.199, val_loss 2.212 \ntrain_acc 0.237, train_loss 2.145\nval_acc 0.241, val_loss 2.118 \ntrain_acc 0.265, train_loss 2.069\nval_acc 0.307, val_loss 1.992 \ntrain_acc 0.283, train_loss 2.018\nval_acc 0.322, val_loss 1.932 \ntrain_acc 0.299, train_loss 1.975\nval_acc 0.304, val_loss 1.944 \ntrain_acc 0.318, train_loss 1.945\nval_acc 0.355, val_loss 1.851 \ntrain_acc 0.329, train_loss 1.912\nval_acc 0.364, val_loss 1.813 \ntrain_acc 0.340, train_loss 1.883\nval_acc 0.387, val_loss 1.779 \ntrain_acc 0.348, train_loss 1.857\nval_acc 0.361, val_loss 1.810 \ntrain_acc 0.355, train_loss 1.838\nval_acc 0.385, val_loss 1.760 \ntrain_acc 0.358, train_loss 1.820\nval_acc 0.404, val_loss 1.725 \ntrain_acc 0.372, train_loss 1.808\nval_acc 0.396, val_loss 1.735 \ntrain_acc 0.371, train_loss 1.803\nval_acc 0.414, val_loss 1.718 \ntrain_acc 0.342, train_loss 1.873\nval_acc 0.361, val_loss 1.800 \ntrain_acc 0.354, train_loss 1.830\nval_acc 0.358, val_loss 1.810 \ntrain_acc 0.371, train_loss 1.792\nval_acc 0.408, val_loss 1.680 \ntrain_acc 0.394, train_loss 1.747\nval_acc 0.424, val_loss 1.671 \ntrain_acc 0.398, train_loss 1.722\nval_acc 0.442, val_loss 1.601 \ntrain_acc 0.415, train_loss 1.677\nval_acc 0.451, val_loss 1.587 \ntrain_acc 0.415, train_loss 1.660\nval_acc 0.484, val_loss 1.519 \ntrain_acc 0.437, train_loss 1.609\nval_acc 0.459, val_loss 1.543 \ntrain_acc 0.440, train_loss 1.597\nval_acc 0.449, val_loss 1.575 \ntrain_acc 0.458, train_loss 1.554\nval_acc 0.505, val_loss 1.479 \ntrain_acc 0.479, train_loss 1.516\nval_acc 0.513, val_loss 1.452 \ntrain_acc 0.475, train_loss 1.507\nval_acc 0.525, val_loss 1.415 \ntrain_acc 0.486, train_loss 1.467\nval_acc 0.504, val_loss 1.465 \ntrain_acc 0.493, train_loss 1.462\nval_acc 0.531, val_loss 1.381 \ntrain_acc 0.495, train_loss 1.452\nval_acc 0.516, val_loss 1.408 \ntrain_acc 0.501, train_loss 1.430\nval_acc 0.526, val_loss 1.382 \ntrain_acc 0.464, train_loss 1.566\nval_acc 0.448, val_loss 1.610 \ntrain_acc 0.463, train_loss 1.553\nval_acc 0.478, val_loss 1.512 \ntrain_acc 0.467, train_loss 1.533\nval_acc 0.504, val_loss 1.429 \ntrain_acc 0.479, train_loss 1.509\nval_acc 0.517, val_loss 1.425 \ntrain_acc 0.478, train_loss 1.494\nval_acc 0.455, val_loss 1.547 \ntrain_acc 0.491, train_loss 1.468\nval_acc 0.515, val_loss 1.423 \ntrain_acc 0.501, train_loss 1.436\nval_acc 0.480, val_loss 1.495 \ntrain_acc 0.510, train_loss 1.411\nval_acc 0.507, val_loss 1.468 \ntrain_acc 0.515, train_loss 1.395\nval_acc 0.555, val_loss 1.312 \ntrain_acc 0.531, train_loss 1.352\nval_acc 0.521, val_loss 1.384 \ntrain_acc 0.534, train_loss 1.342\nval_acc 0.565, val_loss 1.253 \ntrain_acc 0.547, train_loss 1.293\nval_acc 0.550, val_loss 1.294 \ntrain_acc 0.549, train_loss 1.300\nval_acc 0.564, val_loss 1.252 \ntrain_acc 0.554, train_loss 1.283\nval_acc 0.571, val_loss 1.241 \ntrain_acc 0.565, train_loss 1.249\nval_acc 0.573, val_loss 1.240 \ntrain_acc 0.569, train_loss 1.241\nval_acc 0.569, val_loss 1.246 \ntrain_acc 0.500, train_loss 1.453\nval_acc 0.528, val_loss 1.381 \ntrain_acc 0.524, train_loss 1.386\nval_acc 0.511, val_loss 1.414 \ntrain_acc 0.518, train_loss 1.388\nval_acc 0.545, val_loss 1.300 \ntrain_acc 0.526, train_loss 1.370\nval_acc 0.551, val_loss 1.307 \ntrain_acc 0.534, train_loss 1.330\nval_acc 0.496, val_loss 1.427 \ntrain_acc 0.547, train_loss 1.304\nval_acc 0.524, val_loss 1.372 \ntrain_acc 0.554, train_loss 1.298\nval_acc 0.556, val_loss 1.276 \ntrain_acc 0.563, train_loss 1.266\nval_acc 0.510, val_loss 1.434 \ntrain_acc 0.565, train_loss 1.253\nval_acc 0.571, val_loss 1.237 \ntrain_acc 0.578, train_loss 1.221\nval_acc 0.580, val_loss 1.221 \ntrain_acc 0.586, train_loss 1.192\nval_acc 0.563, val_loss 1.249 \ntrain_acc 0.590, train_loss 1.184\nval_acc 0.606, val_loss 1.160 \ntrain_acc 0.597, train_loss 1.168\nval_acc 0.609, val_loss 1.157 \ntrain_acc 0.608, train_loss 1.121\nval_acc 0.611, val_loss 1.144 \ntrain_acc 0.606, train_loss 1.128\nval_acc 0.611, val_loss 1.152 \ntrain_acc 0.616, train_loss 1.105\nval_acc 0.617, val_loss 1.134 \ntrain_acc 0.562, train_loss 1.270\nval_acc 0.531, val_loss 1.397 \ntrain_acc 0.568, train_loss 1.268\nval_acc 0.538, val_loss 1.404 \ntrain_acc 0.567, train_loss 1.247\nval_acc 0.567, val_loss 1.282 \ntrain_acc 0.579, train_loss 1.215\nval_acc 0.537, val_loss 1.344 \ntrain_acc 0.576, train_loss 1.223\nval_acc 0.600, val_loss 1.165 \ntrain_acc 0.583, train_loss 1.197\nval_acc 0.578, val_loss 1.257 \ntrain_acc 0.587, train_loss 1.190\nval_acc 0.559, val_loss 1.235 \ntrain_acc 0.604, train_loss 1.143\nval_acc 0.599, val_loss 1.196 \ntrain_acc 0.607, train_loss 1.131\nval_acc 0.614, val_loss 1.144 \ntrain_acc 0.619, train_loss 1.095\nval_acc 0.618, val_loss 1.138 \ntrain_acc 0.634, train_loss 1.067\nval_acc 0.619, val_loss 1.131 \ntrain_acc 0.633, train_loss 1.055\nval_acc 0.626, val_loss 1.104 \ntrain_acc 0.641, train_loss 1.057\nval_acc 0.620, val_loss 1.127 \ntrain_acc 0.644, train_loss 1.030\nval_acc 0.626, val_loss 1.097 \ntrain_acc 0.649, train_loss 1.017\nval_acc 0.633, val_loss 1.078 \n","output_type":"stream"}]},{"cell_type":"code","source":"test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=test_tfm)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\ntest_loaders = []\nfor i in range(5):\n    test_set_i = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=train_tfm)\n    test_loader_i = DataLoader(test_set_i, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n    test_loaders.append(test_loader_i)\n    ","metadata":{"papermill":{"duration":0.493644,"end_time":"2022-02-23T19:10:19.985992","exception":false,"start_time":"2022-02-23T19:10:19.492348","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing and generate prediction CSV","metadata":{"papermill":{"duration":0.498773,"end_time":"2022-02-23T19:10:20.961802","exception":false,"start_time":"2022-02-23T19:10:20.463029","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\n","metadata":{"papermill":{"duration":32830.720158,"end_time":"2022-02-23T19:10:19.001001","exception":false,"start_time":"2022-02-23T10:03:08.280843","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor i in (config['num_folds']):\n    models[i]=Classifier().to(device)\n    models[i].load_state_dict(torch.load( config['model_path'] + f\"Fold_{i}_best\"))\n    models[i].eval()\n    \nwith torch.no_grad():\n    for data, _ in test_loader:\n        batch_preds = [] \n        for model_best in models:\n            batch_preds.append(model_best(data.to(devices[0])).cpu().data.numpy())\n        batch_preds = sum(batch_preds)\n        preds[0].extend(batch_preds.squeeze().tolist())    \n    \n    for i, loader in enumerate(test_loaders):\n        for data, _ in loader:\n            batch_preds = []\n            for model_best in models:\n                batch_preds.append(model_best(data.to(devices[0])).cpu().data.numpy())\n            batch_preds = sum(batch_preds)\n            preds[i+1].extend(batch_preds.squeeze().tolist())\n            \n    preds_np = np.array(preds, dtype=object)\n    print(preds_np.shape)\n    bb = 0.6* preds_np[0] + 0.1 * preds_np[1] + 0.1 * preds_np[2] + 0.1 * preds_np[3] + 0.1 * preds_np[4] + 0.1 * preds_np[5]\n    print(bb.shape)\n    prediction = np.argmax(bb, axis=1)\n\n","metadata":{"papermill":{"duration":49.157727,"end_time":"2022-02-23T19:11:10.61523","exception":false,"start_time":"2022-02-23T19:10:21.457503","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create test csv\ndef pad4(i):\n    return \"0\"*(4-len(str(i)))+str(i)\ndf = pd.DataFrame()\ndf[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\ndf[\"Category\"] = prediction\ndf.to_csv(\"submission.csv\",index = False)","metadata":{"papermill":{"duration":0.554276,"end_time":"2022-02-23T19:11:11.870035","exception":false,"start_time":"2022-02-23T19:11:11.315759","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}